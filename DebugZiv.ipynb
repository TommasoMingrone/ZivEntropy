{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated random binary string:\n",
      "tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Generating a random binary string of length 50\n",
    "string_length = 50\n",
    "random_string = torch.randint(0, 2, (string_length,)).float()\n",
    "\n",
    "# Parameters\n",
    "num_kernel = 10  # Number of kernels\n",
    "M = 5            # Maximum kernel length\n",
    "eps = 0.5        # Epsilon for relu_distance calculation\n",
    "epochs = 10      # Number of epochs for optimization\n",
    "lr = 0.01        # Learning rate\n",
    "\n",
    "# Debug: Print the generated random string\n",
    "print(\"Generated random binary string:\")\n",
    "print(random_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seqs(nn.Module):\n",
    "    def __init__(self, dim, num_kernels):\n",
    "        super(Seqs, self).__init__()\n",
    "        self.dim = dim  # Kernel length\n",
    "        self.num_kernels = num_kernels  # Number of kernels\n",
    "        self.p = nn.Parameter(torch.rand(num_kernels, dim, dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "    def forward(self):\n",
    "        # Debug: Check that the parameter p requires gradients\n",
    "        print(f\"Parameter p (before forward, requires_grad={self.p.requires_grad}):\\n{self.p}\")\n",
    "\n",
    "        # Forward computation\n",
    "        prob = self.p  # Kernel probabilities\n",
    "        logits = torch.stack((prob, 1 - prob), dim=-1)\n",
    "\n",
    "        # Debug: Check that logits is connected to the computation graph\n",
    "        print(f\"Logits grad_fn: {logits.grad_fn}\")\n",
    "\n",
    "        S = F.gumbel_softmax(logits, tau=0.1, hard=True, dim=-1)[..., 0]\n",
    "\n",
    "        # Debug: Check that S is connected to the computation graph\n",
    "        print(f\"Output S (grad_fn={S.grad_fn}):\\n{S}\")\n",
    "\n",
    "        return S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.6884, 0.2354],\n",
      "        [0.4138, 0.6820],\n",
      "        [0.5644, 0.5714]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x14842e3d0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x14842e3d0>):\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.]], grad_fn=<SelectBackward0>)\n",
      "Gradient of p after backward:\n",
      "tensor([[1.4576e+00, 8.8898e-10],\n",
      "        [2.4518e-10, 7.3460e-08],\n",
      "        [6.3319e-02, 4.3073e-11]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Example of usage during training\n",
    "seq_model = Seqs(2, 3)  # Model with dimension 2 and 3 kernels\n",
    "optimizer = torch.optim.Adam(seq_model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy input\n",
    "input_string = torch.randint(0, 2, (10,)).float()  # Random binary string\n",
    "\n",
    "# Forward pass\n",
    "output = seq_model()\n",
    "\n",
    "# Dummy loss\n",
    "loss = output.sum()\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Debug: Gradient of p\n",
    "print(f\"Gradient of p after backward:\\n{seq_model.p.grad}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3802],\n",
      "        [0.7094],\n",
      "        [0.4730],\n",
      "        [0.1764],\n",
      "        [0.0775],\n",
      "        [0.8040],\n",
      "        [0.5420],\n",
      "        [0.7895],\n",
      "        [0.4264],\n",
      "        [0.9264]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x14842e3d0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x14842e3d0>):\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[1.1231e-01, 2.9194e-04],\n",
      "        [3.6154e-01, 9.6471e-01],\n",
      "        [6.7084e-01, 7.9684e-02],\n",
      "        [3.1580e-01, 1.8933e-01],\n",
      "        [3.0300e-01, 2.6501e-01],\n",
      "        [6.6091e-01, 4.7134e-01],\n",
      "        [9.4994e-01, 2.5308e-01],\n",
      "        [9.7226e-01, 5.3829e-01],\n",
      "        [8.3720e-01, 6.1209e-01],\n",
      "        [1.9945e-01, 8.1742e-01]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x14842e3d0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x14842e3d0>):\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3711, 0.5723, 0.5745],\n",
      "        [0.1389, 0.6268, 0.9444],\n",
      "        [0.6420, 0.2329, 0.1013],\n",
      "        [0.5958, 0.7571, 0.4763],\n",
      "        [0.2276, 0.4533, 0.5067],\n",
      "        [0.6651, 0.0270, 0.6891],\n",
      "        [0.1227, 0.3431, 0.2943],\n",
      "        [0.7575, 0.2931, 0.8147],\n",
      "        [0.7417, 0.1893, 0.2305],\n",
      "        [0.4290, 0.6358, 0.2109]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x14842e3d0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x14842e3d0>):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3609, 0.1225, 0.3602, 0.8367],\n",
      "        [0.5481, 0.9038, 0.6715, 0.3587],\n",
      "        [0.0357, 0.2489, 0.0505, 0.8464],\n",
      "        [0.8122, 0.6980, 0.6408, 0.8796],\n",
      "        [0.7243, 0.0825, 0.4630, 0.1571],\n",
      "        [0.4844, 0.7299, 0.4036, 0.4484],\n",
      "        [0.4420, 0.4189, 0.6832, 0.4987],\n",
      "        [0.9378, 0.3036, 0.4033, 0.5787],\n",
      "        [0.1074, 0.4593, 0.9191, 0.9184],\n",
      "        [0.6745, 0.3729, 0.8934, 0.8450]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x14842e3d0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x14842e3d0>):\n",
      "tensor([[1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.9068, 0.5975, 0.6900, 0.2230, 0.5232],\n",
      "        [0.7833, 0.2087, 0.8340, 0.2898, 0.8154],\n",
      "        [0.0572, 0.7399, 0.3633, 0.1880, 0.1100],\n",
      "        [0.6108, 0.2140, 0.8632, 0.4794, 0.4654],\n",
      "        [0.0938, 0.7355, 0.1644, 0.0746, 0.2452],\n",
      "        [0.2900, 0.2801, 0.5395, 0.5402, 0.4657],\n",
      "        [0.7053, 0.4471, 0.5742, 0.5784, 0.3104],\n",
      "        [0.0495, 0.2313, 0.2026, 0.2896, 0.0767],\n",
      "        [0.2984, 0.0295, 0.4853, 0.4616, 0.7180],\n",
      "        [0.4173, 0.1402, 0.7811, 0.6957, 0.5163]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x14842e3d0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x14842e3d0>):\n",
      "tensor([[1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 0.]], grad_fn=<SelectBackward0>)\n",
      "Binary kernels (dim 1):\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]], grad_fn=<SelectBackward0>)\n",
      "Binary kernels (dim 2):\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Binary kernels (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.]], grad_fn=<SelectBackward0>)\n",
      "Binary kernels (dim 4):\n",
      "tensor([[1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]], grad_fn=<SelectBackward0>)\n",
      "Binary kernels (dim 5):\n",
      "tensor([[1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 1.],\n",
      "        [0., 1., 1., 0., 0.]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate a model for each dimension from 1 to M\n",
    "seq_models = [Seqs(dim, num_kernel) for dim in range(1, M + 1)]\n",
    "\n",
    "# Generate binary kernels directly from the model (without detach)\n",
    "binary_kernels = [model() for model in seq_models]\n",
    "\n",
    "# Debug: Display the generated binary kernels\n",
    "for dim, kernels in enumerate(binary_kernels, start=1):\n",
    "    print(f\"Binary kernels (dim {dim}):\")\n",
    "    print(kernels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZivEntropy(binary_kernels, string, eps=0.5):\n",
    "\n",
    "    ziv_probs = []\n",
    "\n",
    "    for k, kernels in enumerate(binary_kernels, start=1):\n",
    "        # Generate patches of length k\n",
    "        patches = string.unfold(0, k, 1)\n",
    "\n",
    "        # Debug: Check that patches are part of the computational graph\n",
    "        print(f\"Patches (k={k}): requires_grad={patches.requires_grad}, shape={patches.shape}\")\n",
    "\n",
    "        # Manual calculation of Manhattan distances\n",
    "        distances = torch.abs(patches.unsqueeze(1) - kernels.unsqueeze(0)).sum(dim=-1)\n",
    "\n",
    "        # Debug: Check that distances are part of the computational graph\n",
    "        print(f\"Manhattan distances (k={k}): requires_grad={distances.requires_grad}, grad_fn={distances.grad_fn}\")\n",
    "\n",
    "        # ReLU distance calculations\n",
    "        relu_distances = F.relu(eps - distances + 1e-6) / eps\n",
    "\n",
    "        # Debug: Check that relu_distances are connected to the graph\n",
    "        print(f\"ReLU distances (k={k}): requires_grad={relu_distances.requires_grad}, grad_fn={relu_distances.grad_fn}\")\n",
    "\n",
    "        # Probability calculations\n",
    "        probs = relu_distances.sum(dim=0) / (len(patches) * num_kernel)\n",
    "\n",
    "        # Debug: Check that probs are connected to the graph\n",
    "        print(f\"Probabilities (unnormalized) (k={k}): requires_grad={probs.requires_grad}, grad_fn={probs.grad_fn}\")\n",
    "\n",
    "        # Normalization of probabilities\n",
    "        normalized_probs = probs / probs.sum()\n",
    "\n",
    "        # Debug: Check that normalized_probs support gradients\n",
    "        print(f\"Normalized probabilities (k={k}): requires_grad={normalized_probs.requires_grad}, grad_fn={normalized_probs.grad_fn}\")\n",
    "\n",
    "        ziv_probs.append(normalized_probs)\n",
    "\n",
    "    return ziv_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.0627, 0.4270, 0.0088],\n",
      "        [0.9394, 0.7750, 0.8359],\n",
      "        [0.2598, 0.8644, 0.7223],\n",
      "        [0.6523, 0.7576, 0.7315],\n",
      "        [0.0292, 0.4759, 0.1184]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x168da4610>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x168da4610>):\n",
      "tensor([[1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.]], grad_fn=<SelectBackward0>)\n",
      "Binary kernel 1: requires_grad=True\n",
      "Does the binary string require gradients? True\n",
      "Patches (k=1): requires_grad=True, shape=torch.Size([10, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x168da4220>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x168da4220>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x168da4220>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x168da4220>\n",
      "Normalized probabilities (dim=1):\n",
      "tensor([nan, nan, nan, nan, nan], grad_fn=<DivBackward0>)\n",
      "Probabilities grad_fn: <DivBackward0 object at 0x168da48b0>\n",
      "Do probabilities (dim=1) require gradients? True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Test of the ZivEntropy function with an example\n",
    "dim = 3  # Kernel dimension\n",
    "num_kernels = 5  # Number of kernels\n",
    "string_length = 10  # Length of the binary string\n",
    "\n",
    "# Creating a Seqs model\n",
    "seq_model = Seqs(dim, num_kernels)\n",
    "\n",
    "# Generating binary kernels\n",
    "binary_kernels = [seq_model()]  # Simulating one dimension with binary kernels\n",
    "\n",
    "# Debug: Check that the binary kernels are connected to the computation graph\n",
    "for kernel_index, kernel in enumerate(binary_kernels, start=1):\n",
    "    print(f\"Binary kernel {kernel_index}: requires_grad={kernel.requires_grad}\")\n",
    "\n",
    "# Generating a random binary string\n",
    "random_string = torch.randint(0, 2, (string_length,), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Debug: Check if the binary string requires gradients\n",
    "print(f\"Does the binary string require gradients? {'True' if random_string.requires_grad else 'False'}\")\n",
    "\n",
    "# Epsilon\n",
    "eps = 0.5\n",
    "\n",
    "# Test of the ZivEntropy function\n",
    "ziv_probs = ZivEntropy(binary_kernels, random_string, eps=eps)\n",
    "\n",
    "# Debug: Print probabilities to verify connection to the computation graph\n",
    "for k, probs in enumerate(ziv_probs, start=1):\n",
    "    print(f\"Normalized probabilities (dim={k}):\\n{probs}\")\n",
    "    print(f\"Probabilities grad_fn: {probs.grad_fn}\")\n",
    "    print(f\"Do probabilities (dim={k}) require gradients? {'True' if probs.requires_grad else 'False'}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZivEntropyLoss(ziv_probs):\n",
    "\n",
    "    entropies_per_dim = []\n",
    "\n",
    "    for dim_index, probs in enumerate(ziv_probs, start=1):\n",
    "        # Avoid division by 0 and log(0) by adding a small epsilon\n",
    "        probs = probs + 1e-8\n",
    "\n",
    "        # Compute H for each probability value\n",
    "        H_values = -(probs * probs.log())\n",
    "\n",
    "        # Compute the mean of H for this dimension\n",
    "        H_mean = H_values.mean()\n",
    "\n",
    "        # Debug: Print the entropy calculated for the current dimension\n",
    "        print(f\"Entropy calculated for dimension {dim_index} (mean): {H_mean.item()}\")\n",
    "\n",
    "        entropies_per_dim.append(H_mean)\n",
    "\n",
    "    # Sum the mean entropies across all dimensions\n",
    "    Entropies = torch.stack(entropies_per_dim).sum()\n",
    "    full_entropy = torch.mean(Entropies)\n",
    "\n",
    "    # Debug: Print the full entropy\n",
    "    print(f\"Calculated Full Entropy: {full_entropy.item()}\")\n",
    "\n",
    "    return full_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension 1: requires_grad=True\n",
      "Dimension 2: requires_grad=True\n",
      "Dimension 3: requires_grad=True\n",
      "Entropy calculated for dimension 1 (mean): 0.3432177007198334\n",
      "Entropy calculated for dimension 2 (mean): 0.31996357440948486\n",
      "Entropy calculated for dimension 3 (mean): 0.34153974056243896\n",
      "Calculated Full Entropy: 1.0047210454940796\n",
      "Does Full Entropy require gradients? True\n",
      "Gradient for probabilities of dimension 1: tensor([ 0.2031,  0.0680, -0.1023])\n",
      "Is gradient computed for dim 1? True\n",
      "Gradient for probabilities of dimension 2: tensor([ 0.3256,  0.1524, -0.0209,  0.0510])\n",
      "Is gradient computed for dim 2? True\n",
      "Gradient for probabilities of dimension 3: tensor([0.0510, 0.0510, 0.1524, 0.1524])\n",
      "Is gradient computed for dim 3? True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Test of the ZivEntropyLoss function\n",
    "\n",
    "# Simulate normalized probabilities generated by ZivEntropy\n",
    "ziv_probs = [\n",
    "    torch.tensor([0.2, 0.3, 0.5], requires_grad=True),  # Probabilities for dim=1\n",
    "    torch.tensor([0.1, 0.2, 0.4, 0.3], requires_grad=True),  # Probabilities for dim=2\n",
    "    torch.tensor([0.3, 0.3, 0.2, 0.2], requires_grad=True)  # Probabilities for dim=3\n",
    "]\n",
    "\n",
    "# Debug: Check if tensors in ziv_probs require gradients\n",
    "for dim_index, probs in enumerate(ziv_probs, start=1):\n",
    "    print(f\"Dimension {dim_index}: requires_grad={probs.requires_grad}\")\n",
    "\n",
    "# Compute the loss\n",
    "full_entropy = ZivEntropyLoss(ziv_probs)\n",
    "\n",
    "# Debug: Check connection to the computation graph for full_entropy\n",
    "print(f\"Does Full Entropy require gradients? {'True' if full_entropy.grad_fn is not None else 'False'}\")\n",
    "\n",
    "# Backpropagation to verify gradients\n",
    "full_entropy.backward()\n",
    "\n",
    "# Debug: Print gradients for each dimension\n",
    "for dim_index, probs in enumerate(ziv_probs, start=1):\n",
    "    print(f\"Gradient for probabilities of dimension {dim_index}: {probs.grad}\")\n",
    "    print(f\"Is gradient computed for dim {dim_index}? {'True' if probs.grad is not None else 'False'}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x148432a30>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x148432a30>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x148432a30>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x148432a30>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x148432a30>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x148432a30>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 1): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 2): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 3): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 4): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 5): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 6): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 7): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 8): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1550d0100>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1550d0100>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 9): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Patches (k=1): requires_grad=False, shape=torch.Size([50, 1])\n",
      "Manhattan distances (k=1): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=1): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=2): requires_grad=False, shape=torch.Size([49, 2])\n",
      "Manhattan distances (k=2): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=2): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=3): requires_grad=False, shape=torch.Size([48, 3])\n",
      "Manhattan distances (k=3): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=3): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=4): requires_grad=False, shape=torch.Size([47, 4])\n",
      "Manhattan distances (k=4): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=4): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Patches (k=5): requires_grad=False, shape=torch.Size([46, 5])\n",
      "Manhattan distances (k=5): requires_grad=True, grad_fn=<SumBackward1 object at 0x1071a0af0>\n",
      "ReLU distances (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Probabilities (unnormalized) (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Normalized probabilities (k=5): requires_grad=True, grad_fn=<DivBackward0 object at 0x1071a0af0>\n",
      "Entropy calculated for dimension 1 (mean): 0.23017850518226624\n",
      "Entropy calculated for dimension 2 (mean): 0.23020561039447784\n",
      "Entropy calculated for dimension 3 (mean): 0.22946760058403015\n",
      "Entropy calculated for dimension 4 (mean): 0.22448325157165527\n",
      "Entropy calculated for dimension 5 (mean): 0.21383336186408997\n",
      "Calculated Full Entropy: 1.1281683444976807\n",
      "Full Entropy (Epoch 10): 1.1281683444976807\n",
      "Kernel gradients (dim 1):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Kernel gradients (dim 2):\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Kernel gradients (dim 3):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Kernel gradients (dim 4):\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Kernel gradients (dim 5):\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Optimizer for the model parameters\n",
    "optimizer = torch.optim.Adam([param for model in seq_models for param in model.parameters()], lr=lr)\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "    # Calculate probabilities using ZivEntropy\n",
    "    ziv_probs = ZivEntropy(binary_kernels, random_string, eps=eps)\n",
    "\n",
    "    # Calculate the loss\n",
    "    full_entropy = ZivEntropyLoss(ziv_probs)\n",
    "\n",
    "    # Save the loss to the list\n",
    "    losses.append(full_entropy.item())\n",
    "\n",
    "    # Backpropagation\n",
    "    full_entropy.backward(retain_graph=True)\n",
    "\n",
    "    # Debug: Display the total entropy\n",
    "    print(f\"Full Entropy (Epoch {epoch + 1}): {full_entropy.item()}\")\n",
    "\n",
    "    # Debug: Gradients for each dimension\n",
    "    for dim, model in enumerate(seq_models, start=1):\n",
    "        print(f\"Kernel gradients (dim {dim}):\\n{model.p.grad}\")\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Full Entropy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel 1 requires_grad: True\n",
      "Kernel 2 requires_grad: True\n",
      "Kernel 3 requires_grad: True\n",
      "Kernel 4 requires_grad: True\n",
      "Kernel 5 requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(seq_models):\n",
    "    print(f\"Kernel {i + 1} requires_grad: {model.p.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test gradient for kernel 5: tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "test_loss = seq_models[4].p.sum()  # Compute the sum of the parameter p for the model with dimension 5\n",
    "test_loss.backward()  # Backpropagation to calculate gradients\n",
    "\n",
    "# Print the gradient of the parameter p for the model with dimension 5\n",
    "print(f\"Test gradient for kernel 5: {seq_models[4].p.grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated values for the kernel with dimension 5 (p):\n",
      "tensor([[0.9019, 0.5926, 0.6852, 0.2181, 0.5184],\n",
      "        [0.7784, 0.2038, 0.8291, 0.2850, 0.8106],\n",
      "        [0.0524, 0.7350, 0.3585, 0.1832, 0.1052],\n",
      "        [0.6060, 0.2092, 0.8584, 0.4746, 0.4606],\n",
      "        [0.0890, 0.7307, 0.1595, 0.0697, 0.2404],\n",
      "        [0.2852, 0.2753, 0.5347, 0.5354, 0.4609],\n",
      "        [0.7004, 0.4422, 0.5694, 0.5735, 0.3056],\n",
      "        [0.0447, 0.2264, 0.1978, 0.2848, 0.0719],\n",
      "        [0.2936, 0.0247, 0.4805, 0.4568, 0.7132],\n",
      "        [0.4125, 0.1354, 0.7763, 0.6909, 0.5115]])\n"
     ]
    }
   ],
   "source": [
    "# Optimization\n",
    "optimizer.step()  # Update parameters\n",
    "\n",
    "# Check the updated kernel values for the model with dimension 5\n",
    "print(f\"Updated values for the kernel with dimension 5 (p):\\n{seq_models[4].p.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3802],\n",
      "        [0.7094],\n",
      "        [0.4730],\n",
      "        [0.1764],\n",
      "        [0.0775],\n",
      "        [0.8040],\n",
      "        [0.5420],\n",
      "        [0.7895],\n",
      "        [0.4264],\n",
      "        [0.9264]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x168d8c820>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x168d8c820>):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[1.1231e-01, 2.9194e-04],\n",
      "        [3.6154e-01, 9.6471e-01],\n",
      "        [6.7084e-01, 7.9684e-02],\n",
      "        [3.1580e-01, 1.8933e-01],\n",
      "        [3.0300e-01, 2.6501e-01],\n",
      "        [6.6091e-01, 4.7134e-01],\n",
      "        [9.4994e-01, 2.5308e-01],\n",
      "        [9.7226e-01, 5.3829e-01],\n",
      "        [8.3720e-01, 6.1209e-01],\n",
      "        [1.9945e-01, 8.1742e-01]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x168d8c820>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x168d8c820>):\n",
      "tensor([[0., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3711, 0.5723, 0.5745],\n",
      "        [0.1389, 0.6268, 0.9444],\n",
      "        [0.6420, 0.2329, 0.1013],\n",
      "        [0.5958, 0.7571, 0.4763],\n",
      "        [0.2276, 0.4533, 0.5067],\n",
      "        [0.6651, 0.0270, 0.6891],\n",
      "        [0.1227, 0.3431, 0.2943],\n",
      "        [0.7575, 0.2931, 0.8147],\n",
      "        [0.7417, 0.1893, 0.2305],\n",
      "        [0.4290, 0.6358, 0.2109]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x168d8c820>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x168d8c820>):\n",
      "tensor([[1., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 1., 0.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3609, 0.1225, 0.3602, 0.8367],\n",
      "        [0.5481, 0.9038, 0.6715, 0.3587],\n",
      "        [0.0357, 0.2489, 0.0505, 0.8464],\n",
      "        [0.8122, 0.6980, 0.6408, 0.8796],\n",
      "        [0.7243, 0.0825, 0.4630, 0.1571],\n",
      "        [0.4844, 0.7299, 0.4036, 0.4484],\n",
      "        [0.4420, 0.4189, 0.6832, 0.4987],\n",
      "        [0.9378, 0.3036, 0.4033, 0.5787],\n",
      "        [0.1074, 0.4593, 0.9191, 0.9184],\n",
      "        [0.6745, 0.3729, 0.8934, 0.8450]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x168d8c820>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x168d8c820>):\n",
      "tensor([[1., 0., 0., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.9019, 0.5926, 0.6852, 0.2181, 0.5184],\n",
      "        [0.7784, 0.2038, 0.8291, 0.2850, 0.8106],\n",
      "        [0.0524, 0.7350, 0.3585, 0.1832, 0.1052],\n",
      "        [0.6060, 0.2092, 0.8584, 0.4746, 0.4606],\n",
      "        [0.0890, 0.7307, 0.1595, 0.0697, 0.2404],\n",
      "        [0.2852, 0.2753, 0.5347, 0.5354, 0.4609],\n",
      "        [0.7004, 0.4422, 0.5694, 0.5735, 0.3056],\n",
      "        [0.0447, 0.2264, 0.1978, 0.2848, 0.0719],\n",
      "        [0.2936, 0.0247, 0.4805, 0.4568, 0.7132],\n",
      "        [0.4125, 0.1354, 0.7763, 0.6909, 0.5115]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x168d8c820>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x168d8c820>):\n",
      "tensor([[0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Generated binary kernel for Dim 5:\n",
      "tensor([[0., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [1., 1., 0., 0., 1.]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Apply forward pass for all models\n",
    "binary_kernels = [seq_model() for seq_model in seq_models]\n",
    "\n",
    "# Print the binary kernel result corresponding to dimension 5\n",
    "print(\"Generated binary kernel for Dim 5:\")\n",
    "print(binary_kernels[4])  # The kernel for dimension 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities (dim 1): tensor([0.1040, 0.0960, 0.0960, 0.1040, 0.0960, 0.1040, 0.0960, 0.1040, 0.0960,\n",
      "        0.1040], grad_fn=<DivBackward0>)\n",
      "Probabilities (dim 2): tensor([0.0984, 0.0984, 0.0984, 0.0984, 0.0984, 0.0984, 0.0984, 0.1066, 0.1066,\n",
      "        0.0984], grad_fn=<DivBackward0>)\n",
      "Probabilities (dim 3): tensor([0.1111, 0.0952, 0.0794, 0.1111, 0.1111, 0.1111, 0.0952, 0.0794, 0.1111,\n",
      "        0.0952], grad_fn=<DivBackward0>)\n",
      "Probabilities (dim 4): tensor([0.0938, 0.1250, 0.0625, 0.1250, 0.1562, 0.1250, 0.1250, 0.0625, 0.0625,\n",
      "        0.0625], grad_fn=<DivBackward0>)\n",
      "Probabilities (dim 5): tensor([0.1667, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.1667, 0.0000, 0.1667,\n",
      "        0.0833], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for dim, probs in enumerate(ziv_probs):\n",
    "    print(f\"Probabilities (dim {dim + 1}): {probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities (Dim 1): 1.0000001192092896\n",
      "Probabilities (Dim 2): 1.0\n",
      "Probabilities (Dim 3): 0.9999999403953552\n",
      "Probabilities (Dim 4): 1.0\n",
      "Probabilities (Dim 5): 0.9999999403953552\n"
     ]
    }
   ],
   "source": [
    "for i, probs in enumerate(ziv_probs):\n",
    "    print(f\"Probabilities (Dim {i + 1}): {probs.sum().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3802],\n",
      "        [0.7094],\n",
      "        [0.4730],\n",
      "        [0.1764],\n",
      "        [0.0775],\n",
      "        [0.8040],\n",
      "        [0.5420],\n",
      "        [0.7895],\n",
      "        [0.4264],\n",
      "        [0.9264]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bc8b0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bc8b0>):\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[1.1231e-01, 2.9194e-04],\n",
      "        [3.6154e-01, 9.6471e-01],\n",
      "        [6.7084e-01, 7.9684e-02],\n",
      "        [3.1580e-01, 1.8933e-01],\n",
      "        [3.0300e-01, 2.6501e-01],\n",
      "        [6.6091e-01, 4.7134e-01],\n",
      "        [9.4994e-01, 2.5308e-01],\n",
      "        [9.7226e-01, 5.3829e-01],\n",
      "        [8.3720e-01, 6.1209e-01],\n",
      "        [1.9945e-01, 8.1742e-01]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bc8b0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bc8b0>):\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3711, 0.5723, 0.5745],\n",
      "        [0.1389, 0.6268, 0.9444],\n",
      "        [0.6420, 0.2329, 0.1013],\n",
      "        [0.5958, 0.7571, 0.4763],\n",
      "        [0.2276, 0.4533, 0.5067],\n",
      "        [0.6651, 0.0270, 0.6891],\n",
      "        [0.1227, 0.3431, 0.2943],\n",
      "        [0.7575, 0.2931, 0.8147],\n",
      "        [0.7417, 0.1893, 0.2305],\n",
      "        [0.4290, 0.6358, 0.2109]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bc8b0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bc8b0>):\n",
      "tensor([[0., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 1., 0.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3609, 0.1225, 0.3602, 0.8367],\n",
      "        [0.5481, 0.9038, 0.6715, 0.3587],\n",
      "        [0.0357, 0.2489, 0.0505, 0.8464],\n",
      "        [0.8122, 0.6980, 0.6408, 0.8796],\n",
      "        [0.7243, 0.0825, 0.4630, 0.1571],\n",
      "        [0.4844, 0.7299, 0.4036, 0.4484],\n",
      "        [0.4420, 0.4189, 0.6832, 0.4987],\n",
      "        [0.9378, 0.3036, 0.4033, 0.5787],\n",
      "        [0.1074, 0.4593, 0.9191, 0.9184],\n",
      "        [0.6745, 0.3729, 0.8934, 0.8450]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bc8b0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bc8b0>):\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [0., 1., 1., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 1., 1.],\n",
      "        [1., 1., 0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.9019, 0.5926, 0.6852, 0.2181, 0.5184],\n",
      "        [0.7784, 0.2038, 0.8291, 0.2850, 0.8106],\n",
      "        [0.0524, 0.7350, 0.3585, 0.1832, 0.1052],\n",
      "        [0.6060, 0.2092, 0.8584, 0.4746, 0.4606],\n",
      "        [0.0890, 0.7307, 0.1595, 0.0697, 0.2404],\n",
      "        [0.2852, 0.2753, 0.5347, 0.5354, 0.4609],\n",
      "        [0.7004, 0.4422, 0.5694, 0.5735, 0.3056],\n",
      "        [0.0447, 0.2264, 0.1978, 0.2848, 0.0719],\n",
      "        [0.2936, 0.0247, 0.4805, 0.4568, 0.7132],\n",
      "        [0.4125, 0.1354, 0.7763, 0.6909, 0.5115]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bc8b0>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bc8b0>):\n",
      "tensor([[1., 1., 1., 0., 1.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 1.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [1., 0., 0., 1., 0.]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "Initial kernel for dimension 1:\n",
      "tensor([[0.3802],\n",
      "        [0.7094],\n",
      "        [0.4730],\n",
      "        [0.1764],\n",
      "        [0.0775],\n",
      "        [0.8040],\n",
      "        [0.5420],\n",
      "        [0.7895],\n",
      "        [0.4264],\n",
      "        [0.9264]])\n",
      "\n",
      "Updated (binary) kernel for dimension 1 after the forward pass:\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "\n",
      "Difference between initial and updated (binary) kernel (dim 1):\n",
      "tensor([[-0.3802],\n",
      "        [-0.7094],\n",
      "        [ 0.5270],\n",
      "        [ 0.8236],\n",
      "        [-0.0775],\n",
      "        [-0.8040],\n",
      "        [-0.5420],\n",
      "        [ 0.2105],\n",
      "        [-0.4264],\n",
      "        [ 0.0736]])\n"
     ]
    }
   ],
   "source": [
    "# Save a copy of the initial kernel for dimension 1\n",
    "initial_dim1_kernel = seq_models[0].p.clone().detach()\n",
    "\n",
    "# Perform the forward pass to generate the binary kernel\n",
    "binary_kernels = [seq_model() for seq_model in seq_models]\n",
    "\n",
    "# Get the updated binary kernel for dimension 1\n",
    "updated_dim1_binary_kernel = binary_kernels[0].detach()\n",
    "\n",
    "# Compare the initial kernel with the updated (binary) kernel after the forward pass\n",
    "print(\"\\nInitial kernel for dimension 1:\")\n",
    "print(initial_dim1_kernel)\n",
    "\n",
    "print(\"\\nUpdated (binary) kernel for dimension 1 after the forward pass:\")\n",
    "print(updated_dim1_binary_kernel)\n",
    "\n",
    "# Difference between the initial kernel and the updated (binary) kernel\n",
    "difference = updated_dim1_binary_kernel - initial_dim1_kernel\n",
    "print(\"\\nDifference between initial and updated (binary) kernel (dim 1):\")\n",
    "print(difference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3802],\n",
      "        [0.7094],\n",
      "        [0.4730],\n",
      "        [0.1764],\n",
      "        [0.0775],\n",
      "        [0.8040],\n",
      "        [0.5420],\n",
      "        [0.7895],\n",
      "        [0.4264],\n",
      "        [0.9264]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bca60>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bca60>):\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[1.1231e-01, 2.9194e-04],\n",
      "        [3.6154e-01, 9.6471e-01],\n",
      "        [6.7084e-01, 7.9684e-02],\n",
      "        [3.1580e-01, 1.8933e-01],\n",
      "        [3.0300e-01, 2.6501e-01],\n",
      "        [6.6091e-01, 4.7134e-01],\n",
      "        [9.4994e-01, 2.5308e-01],\n",
      "        [9.7226e-01, 5.3829e-01],\n",
      "        [8.3720e-01, 6.1209e-01],\n",
      "        [1.9945e-01, 8.1742e-01]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bca60>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bca60>):\n",
      "tensor([[1., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3711, 0.5723, 0.5745],\n",
      "        [0.1389, 0.6268, 0.9444],\n",
      "        [0.6420, 0.2329, 0.1013],\n",
      "        [0.5958, 0.7571, 0.4763],\n",
      "        [0.2276, 0.4533, 0.5067],\n",
      "        [0.6651, 0.0270, 0.6891],\n",
      "        [0.1227, 0.3431, 0.2943],\n",
      "        [0.7575, 0.2931, 0.8147],\n",
      "        [0.7417, 0.1893, 0.2305],\n",
      "        [0.4290, 0.6358, 0.2109]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bca60>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bca60>):\n",
      "tensor([[0., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.3609, 0.1225, 0.3602, 0.8367],\n",
      "        [0.5481, 0.9038, 0.6715, 0.3587],\n",
      "        [0.0357, 0.2489, 0.0505, 0.8464],\n",
      "        [0.8122, 0.6980, 0.6408, 0.8796],\n",
      "        [0.7243, 0.0825, 0.4630, 0.1571],\n",
      "        [0.4844, 0.7299, 0.4036, 0.4484],\n",
      "        [0.4420, 0.4189, 0.6832, 0.4987],\n",
      "        [0.9378, 0.3036, 0.4033, 0.5787],\n",
      "        [0.1074, 0.4593, 0.9191, 0.9184],\n",
      "        [0.6745, 0.3729, 0.8934, 0.8450]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bca60>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bca60>):\n",
      "tensor([[0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.]], grad_fn=<SelectBackward0>)\n",
      "Parameter p (before forward, requires_grad=True):\n",
      "Parameter containing:\n",
      "tensor([[0.9019, 0.5926, 0.6852, 0.2181, 0.5184],\n",
      "        [0.7784, 0.2038, 0.8291, 0.2850, 0.8106],\n",
      "        [0.0524, 0.7350, 0.3585, 0.1832, 0.1052],\n",
      "        [0.6060, 0.2092, 0.8584, 0.4746, 0.4606],\n",
      "        [0.0890, 0.7307, 0.1595, 0.0697, 0.2404],\n",
      "        [0.2852, 0.2753, 0.5347, 0.5354, 0.4609],\n",
      "        [0.7004, 0.4422, 0.5694, 0.5735, 0.3056],\n",
      "        [0.0447, 0.2264, 0.1978, 0.2848, 0.0719],\n",
      "        [0.2936, 0.0247, 0.4805, 0.4568, 0.7132],\n",
      "        [0.4125, 0.1354, 0.7763, 0.6909, 0.5115]], requires_grad=True)\n",
      "Logits grad_fn: <StackBackward0 object at 0x1576bca60>\n",
      "Output S (grad_fn=<SelectBackward0 object at 0x1576bca60>):\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 1.]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "--- Comparison between initial and updated kernels ---\n",
      "Dimension 1:\n",
      "Initial Kernel:\n",
      "tensor([[0.3802],\n",
      "        [0.7094],\n",
      "        [0.4730],\n",
      "        [0.1764],\n",
      "        [0.0775],\n",
      "        [0.8040],\n",
      "        [0.5420],\n",
      "        [0.7895],\n",
      "        [0.4264],\n",
      "        [0.9264]])\n",
      "Updated (binary) Kernel:\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<SelectBackward0>)\n",
      "Difference:\n",
      "tensor([[ 0.6198],\n",
      "        [ 0.2906],\n",
      "        [-0.4730],\n",
      "        [ 0.8236],\n",
      "        [-0.0775],\n",
      "        [ 0.1960],\n",
      "        [-0.5420],\n",
      "        [ 0.2105],\n",
      "        [ 0.5736],\n",
      "        [ 0.0736]], grad_fn=<SubBackward0>)\n",
      "Dimension 2:\n",
      "Initial Kernel:\n",
      "tensor([[1.1231e-01, 2.9194e-04],\n",
      "        [3.6154e-01, 9.6471e-01],\n",
      "        [6.7084e-01, 7.9684e-02],\n",
      "        [3.1580e-01, 1.8933e-01],\n",
      "        [3.0300e-01, 2.6501e-01],\n",
      "        [6.6091e-01, 4.7134e-01],\n",
      "        [9.4994e-01, 2.5308e-01],\n",
      "        [9.7226e-01, 5.3829e-01],\n",
      "        [8.3720e-01, 6.1209e-01],\n",
      "        [1.9945e-01, 8.1742e-01]])\n",
      "Updated (binary) Kernel:\n",
      "tensor([[1., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.]], grad_fn=<SelectBackward0>)\n",
      "Difference:\n",
      "tensor([[ 0.8877,  0.9997],\n",
      "        [-0.3615, -0.9647],\n",
      "        [ 0.3292, -0.0797],\n",
      "        [ 0.6842, -0.1893],\n",
      "        [-0.3030, -0.2650],\n",
      "        [ 0.3391,  0.5287],\n",
      "        [ 0.0501, -0.2531],\n",
      "        [-0.9723, -0.5383],\n",
      "        [-0.8372, -0.6121],\n",
      "        [-0.1994,  0.1826]], grad_fn=<SubBackward0>)\n",
      "Dimension 3:\n",
      "Initial Kernel:\n",
      "tensor([[0.3711, 0.5723, 0.5745],\n",
      "        [0.1389, 0.6268, 0.9444],\n",
      "        [0.6420, 0.2329, 0.1013],\n",
      "        [0.5958, 0.7571, 0.4763],\n",
      "        [0.2276, 0.4533, 0.5067],\n",
      "        [0.6651, 0.0270, 0.6891],\n",
      "        [0.1227, 0.3431, 0.2943],\n",
      "        [0.7575, 0.2931, 0.8147],\n",
      "        [0.7417, 0.1893, 0.2305],\n",
      "        [0.4290, 0.6358, 0.2109]])\n",
      "Updated (binary) Kernel:\n",
      "tensor([[0., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 1., 0.]], grad_fn=<SelectBackward0>)\n",
      "Difference:\n",
      "tensor([[-0.3711, -0.5723,  0.4255],\n",
      "        [ 0.8611,  0.3732, -0.9444],\n",
      "        [ 0.3580, -0.2329,  0.8987],\n",
      "        [-0.5958, -0.7571,  0.5237],\n",
      "        [ 0.7724,  0.5467,  0.4933],\n",
      "        [ 0.3349,  0.9730,  0.3109],\n",
      "        [ 0.8773,  0.6569,  0.7057],\n",
      "        [-0.7575,  0.7069,  0.1853],\n",
      "        [ 0.2583, -0.1893, -0.2305],\n",
      "        [ 0.5710,  0.3642, -0.2109]], grad_fn=<SubBackward0>)\n",
      "Dimension 4:\n",
      "Initial Kernel:\n",
      "tensor([[0.3609, 0.1225, 0.3602, 0.8367],\n",
      "        [0.5481, 0.9038, 0.6715, 0.3587],\n",
      "        [0.0357, 0.2489, 0.0505, 0.8464],\n",
      "        [0.8122, 0.6980, 0.6408, 0.8796],\n",
      "        [0.7243, 0.0825, 0.4630, 0.1571],\n",
      "        [0.4844, 0.7299, 0.4036, 0.4484],\n",
      "        [0.4420, 0.4189, 0.6832, 0.4987],\n",
      "        [0.9378, 0.3036, 0.4033, 0.5787],\n",
      "        [0.1074, 0.4593, 0.9191, 0.9184],\n",
      "        [0.6745, 0.3729, 0.8934, 0.8450]])\n",
      "Updated (binary) Kernel:\n",
      "tensor([[0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.]], grad_fn=<SelectBackward0>)\n",
      "Difference:\n",
      "tensor([[-0.3609, -0.1225, -0.3602,  0.1633],\n",
      "        [ 0.4519,  0.0962,  0.3285, -0.3587],\n",
      "        [-0.0357, -0.2489, -0.0505,  0.1536],\n",
      "        [ 0.1878,  0.3020,  0.3592,  0.1204],\n",
      "        [-0.7243, -0.0825,  0.5370, -0.1571],\n",
      "        [ 0.5156,  0.2701,  0.5964, -0.4484],\n",
      "        [ 0.5580, -0.4189,  0.3168,  0.5013],\n",
      "        [ 0.0622, -0.3036, -0.4033, -0.5787],\n",
      "        [-0.1074, -0.4593, -0.9191, -0.9184],\n",
      "        [ 0.3255,  0.6271,  0.1066,  0.1550]], grad_fn=<SubBackward0>)\n",
      "Dimension 5:\n",
      "Initial Kernel:\n",
      "tensor([[0.9019, 0.5926, 0.6852, 0.2181, 0.5184],\n",
      "        [0.7784, 0.2038, 0.8291, 0.2850, 0.8106],\n",
      "        [0.0524, 0.7350, 0.3585, 0.1832, 0.1052],\n",
      "        [0.6060, 0.2092, 0.8584, 0.4746, 0.4606],\n",
      "        [0.0890, 0.7307, 0.1595, 0.0697, 0.2404],\n",
      "        [0.2852, 0.2753, 0.5347, 0.5354, 0.4609],\n",
      "        [0.7004, 0.4422, 0.5694, 0.5735, 0.3056],\n",
      "        [0.0447, 0.2264, 0.1978, 0.2848, 0.0719],\n",
      "        [0.2936, 0.0247, 0.4805, 0.4568, 0.7132],\n",
      "        [0.4125, 0.1354, 0.7763, 0.6909, 0.5115]])\n",
      "Updated (binary) Kernel:\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 1.]], grad_fn=<SelectBackward0>)\n",
      "Difference:\n",
      "tensor([[ 0.0981,  0.4074, -0.6852, -0.2181,  0.4816],\n",
      "        [-0.7784,  0.7962, -0.8291,  0.7150, -0.8106],\n",
      "        [-0.0524,  0.2650, -0.3585, -0.1832, -0.1052],\n",
      "        [ 0.3940,  0.7908,  0.1416,  0.5254, -0.4606],\n",
      "        [-0.0890, -0.7307,  0.8405,  0.9303, -0.2404],\n",
      "        [-0.2852, -0.2753,  0.4653, -0.5354,  0.5391],\n",
      "        [-0.7004,  0.5578,  0.4306, -0.5735, -0.3056],\n",
      "        [ 0.9553, -0.2264, -0.1978,  0.7152, -0.0719],\n",
      "        [-0.2936,  0.9753,  0.5195, -0.4568, -0.7132],\n",
      "        [-0.4125, -0.1354, -0.7763,  0.3091,  0.4885]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Save a copy of the initial kernels\n",
    "initial_kernels = [seq_model.p.clone().detach() for seq_model in seq_models]\n",
    "\n",
    "# Perform the forward pass to generate the updated binary kernels\n",
    "binary_kernels = [seq_model() for seq_model in seq_models]\n",
    "\n",
    "# Comparison between initial and updated kernels\n",
    "print(\"\\n--- Comparison between initial and updated kernels ---\")\n",
    "for dim_index, (initial_kernel, binary_kernel) in enumerate(zip(initial_kernels, binary_kernels)):\n",
    "    print(f\"Dimension {dim_index + 1}:\")\n",
    "    print(f\"Initial Kernel:\\n{initial_kernel}\")\n",
    "    print(f\"Updated (binary) Kernel:\\n{binary_kernel}\")\n",
    "    difference = binary_kernel - initial_kernel\n",
    "    print(f\"Difference:\\n{difference}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
