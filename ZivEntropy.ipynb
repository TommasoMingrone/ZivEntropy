{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10d5df650>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "SEED = 698\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters\n",
    "N = 50 # Number of strings\n",
    "d = 10000 # Sequence length\n",
    "\n",
    "#Max Kernel size\n",
    "M = 2\n",
    "\n",
    "num_kernels = 20 # Number of kernels per size\n",
    "BATCH_SIZE = 16\n",
    "Lr = 0.1\n",
    "num_epochs = 200 # Number of epochs\n",
    "\n",
    "#Cat=(0,-1,1,2) #Regular\n",
    "Cat=(2,1,1,1) #Chaotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_point(x, y):\n",
    "    if 0 <= x <= 1/2 and 0 <= y <= 1/2:\n",
    "        return 1  \n",
    "    \n",
    "    if 1/2 <= x <= 1 and 1/2 <= y <= 1:\n",
    "        return 1\n",
    "    \n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "\n",
    "def arnold_cat_map_DATA(length,N,Cat):\n",
    "    \n",
    "    \n",
    "    strings=torch.zeros((N,length))\n",
    "    \n",
    "    \n",
    "    # Perform iterations of the map\n",
    "    for i in range(N):\n",
    "        \n",
    "        (x0,y0) = torch.tensor((0,0))+ 0.5 * torch.rand(2)\n",
    "        #(x0,y0) = torch.rand(2)\n",
    "        \n",
    "        a=Cat[0]\n",
    "        b=Cat[1]\n",
    "        c=Cat[2]\n",
    "        d=Cat[3]\n",
    "        \n",
    "        for l in range(length):\n",
    "            \n",
    "            #(x,y) = ((a * x0 + b * y0) % r, (c * x0 + d * y0) % r) # x%n is the reminder  of x/n\n",
    "            (x,y) = ((a * x0 + b * y0) % 1, (c * x0 + d * y0) % 1) # x%1 is the reminder 1  of x\n",
    "            \n",
    "            \n",
    "            strings[i,l] = check_point(x, y)        \n",
    "            \n",
    "            \n",
    "            x0=x\n",
    "            y0=y         \n",
    "\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#data = arnold_cat_map_DATA(d,N,Cat).to(device)\n",
    "#train_data, test_data = torch.split(data, [int(0.8 * N), N - int(0.8 * N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test string\n",
    "data = torch.tensor([\n",
    "    [0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
    "    1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
    "    0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
    "    0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
    "    0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
    "    1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
    "    1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
    "    1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1],\n",
    "]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "         0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "         0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "         1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di 0: 45\n",
      "Numero di 1: 51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of 0\n",
    "num_zeros = torch.sum(data == 0).item()\n",
    "\n",
    "# Count the number of 1\n",
    "num_ones = torch.sum(data == 1).item()\n",
    "\n",
    "print(f\"Numero di 0: {num_zeros}\")\n",
    "print(f\"Numero di 1: {num_ones}\")\n",
    "\n",
    "plt.imshow(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kers(nn.Module):\n",
    "    def __init__(self, max_kernel_size):\n",
    "\n",
    "        super(Kers, self).__init__()\n",
    "        self.max_kernel_size = max_kernel_size\n",
    "        # Initialising a list of learnable parameters for each kernel dimension\n",
    "        self.Ks = nn.ParameterList([nn.Parameter(torch.randn(size, dtype=torch.float32)) for size in range(1, max_kernel_size + 1)])\n",
    "        \n",
    "    def forward(self):\n",
    "        eps = 1e-5\n",
    "        S = [F.relu(kernel + eps) / (kernel + eps) for kernel in self.Ks]\n",
    "        return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelModel(nn.Module):\n",
    "    def __init__(self, M, num_families):\n",
    "        \n",
    "        super(KernelModel, self).__init__()\n",
    "        self.max_kernel_size = M \n",
    "        self.kernels = nn.ModuleList([Kers(max_kernel_size=M) for _ in range(num_families)])\n",
    "\n",
    "    def forward(self, data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZivEntropy(binary_strings, subkernels, BATCH_SIZE):\n",
    "\n",
    "    num_samples, sequence_length = binary_strings.size()\n",
    "    num_subkernels, subkernel_size = subkernels.size()\n",
    "\n",
    "    # Probs tensor to contain the probabilities of all sequences\n",
    "    Probs = torch.zeros(num_samples, num_subkernels, dtype=torch.float32, device=subkernels.device)\n",
    "\n",
    "    # Processing `binary_strings` in multiple batch sizes `BATCH_SIZE`\n",
    "    for i in range(0, num_samples, BATCH_SIZE):\n",
    "        batch_data = binary_strings[i:i + BATCH_SIZE]\n",
    "        current_batch_size = batch_data.size(0)\n",
    "\n",
    "        # Generating patches for each sequence in the current batch\n",
    "        num_patches = sequence_length - subkernel_size + 1\n",
    "        patches = batch_data.unfold(1, subkernel_size, 1)\n",
    "\n",
    "        Probs_batch = torch.zeros(current_batch_size, num_subkernels, dtype=torch.float32, device=subkernels.device)\n",
    "        \n",
    "        for j in range(num_subkernels):\n",
    "            subkernel = subkernels[j].view(1, -1)\n",
    "\n",
    "            eps = 0.5 #***\n",
    "            \n",
    "            # Manhattan distance and probability calculation with Relu\n",
    "            manhattan_distances = torch.abs(patches - subkernel).sum(dim=2)\n",
    "            relu_distances = F.relu(eps - manhattan_distances) / eps\n",
    "            Probs_batch[:, j] = relu_distances.mean(dim=1)\n",
    "\n",
    "        Probs[i:i + current_batch_size] = Probs_batch\n",
    "\n",
    "    #Scaled Probs\n",
    "    total_sum = Probs.sum(dim=1, keepdim=True)\n",
    "    Probs_scaled = torch.where(total_sum != 0, Probs / total_sum, Probs)\n",
    "    #print(\"Scaled Probs:\", Probs_scaled)\n",
    "    return Probs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZivEntropyLoss(data, model, BATCH_SIZE):\n",
    "\n",
    "    entropies_by_size = []\n",
    "    Kernels_list = []\n",
    "\n",
    "    # Iterating on each subkernels dimension\n",
    "    for size in range(1, model.max_kernel_size + 1):\n",
    "        all_subkernels_of_size = []\n",
    "\n",
    "        # Collect all subkernels of this size from all families\n",
    "        for family_idx, kernels in enumerate(model.kernels):\n",
    "            subkernels = kernels()\n",
    "            # Filter and collect only subkernels of the current size\n",
    "            filtered_kernels = [k for k in subkernels if k.size(0) == size]\n",
    "            all_subkernels_of_size.extend(filtered_kernels)\n",
    "\n",
    "        # Stack of subkernels by dimension as a two-dimensional tensor\n",
    "        subkernels_of_size = torch.stack(all_subkernels_of_size)  # (num_subkernels, subkernel_size)\n",
    "        Kernels_list.append(subkernels_of_size)\n",
    "\n",
    "        # Processing `data` in multiple batch sizes `BATCH_SIZE`\n",
    "        num_samples = data.size(0)\n",
    "        entropies_for_batch = []\n",
    "\n",
    "        for i in range(0, num_samples, BATCH_SIZE):\n",
    "            # Extract the current batch\n",
    "            batch_data = data[i:i + BATCH_SIZE]\n",
    "\n",
    "            # Calculating probabilities for all subkernels of this size and batch of data\n",
    "            probs = ZivEntropy(batch_data, subkernels_of_size, BATCH_SIZE)\n",
    "\n",
    "            # Calculating of entropy for the current batch and current size\n",
    "            entropy = -torch.sum(probs * torch.log(probs + 1e-9), dim=1).mean()  # Media su batch corrente\n",
    "            entropies_for_batch.append(entropy)\n",
    "\n",
    "        # Average of batch entropies for this dimension\n",
    "        entropies_by_size.append(torch.mean(torch.stack(entropies_for_batch)))\n",
    "\n",
    "    # Stack of entropies to obtain a list of entropies for each dimension\n",
    "    Entropies = torch.stack(entropies_by_size)\n",
    "    FullEntropy = torch.mean(Entropies)  # Average of entropies as overall entropy\n",
    "\n",
    "    return Entropies, FullEntropy, Kernels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = KernelModel(M, num_kernels).to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=Lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel in the first epoch:\n",
      "Size 1:\n",
      "tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "Size 2:\n",
      "tensor([1., 1.])\n",
      "tensor([1., -0.])\n",
      "tensor([1., 1.])\n",
      "tensor([1., -0.])\n",
      "tensor([1., 1.])\n",
      "tensor([-0., -0.])\n",
      "tensor([-0., 1.])\n",
      "tensor([1., -0.])\n",
      "tensor([1., -0.])\n",
      "tensor([1., -0.])\n",
      "tensor([1., -0.])\n",
      "tensor([-0., 1.])\n",
      "tensor([-0., 1.])\n",
      "tensor([-0., 1.])\n",
      "tensor([1., 1.])\n",
      "tensor([-0., 1.])\n",
      "tensor([-0., -0.])\n",
      "tensor([1., -0.])\n",
      "tensor([-0., 1.])\n",
      "tensor([1., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 5.808372497558594\n",
      "Epoch 20/200, Loss: 3.7670016288757324\n",
      "Epoch 30/200, Loss: 3.353239059448242\n",
      "Epoch 40/200, Loss: 3.120258092880249\n",
      "Epoch 50/200, Loss: 3.038193702697754\n",
      "Epoch 60/200, Loss: 2.997553586959839\n",
      "Epoch 70/200, Loss: 2.9934067726135254\n",
      "Epoch 80/200, Loss: 2.980081081390381\n",
      "Epoch 90/200, Loss: 2.9803149700164795\n",
      "Epoch 100/200, Loss: 2.9850192070007324\n",
      "Epoch 110/200, Loss: 2.983001470565796\n",
      "Epoch 120/200, Loss: 2.979217767715454\n",
      "Epoch 130/200, Loss: 2.9792916774749756\n",
      "Epoch 140/200, Loss: 2.9792685508728027\n",
      "Epoch 150/200, Loss: 2.9792606830596924\n",
      "Epoch 160/200, Loss: 2.979191780090332\n",
      "Epoch 170/200, Loss: 2.979189872741699\n",
      "Epoch 180/200, Loss: 2.9791882038116455\n",
      "Epoch 190/200, Loss: 2.9791877269744873\n",
      "Epoch 200/200, Loss: 2.979187488555908\n"
     ]
    }
   ],
   "source": [
    "# Scheduler for learning rate adjustment\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=list(range(60, num_epochs, 20)), gamma=0.25)\n",
    "losses = []\n",
    "l2_lambda = 5e-1 # \"Encourages\" model parameters to approach zero.\n",
    "positive_lambda = 1e-4 # \"Pushes\" negative values towards positive values\n",
    "\n",
    "# Variable to save kernels from the first epoch\n",
    "initial_kernels = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate the primary loss\n",
    "    Entropies, loss, Kernels = ZivEntropyLoss(data, model, BATCH_SIZE)\n",
    "\n",
    "    # Print the kernels of the first epoch\n",
    "    if epoch == 0:\n",
    "        # Clone each tensor individually inside `Kernels`\n",
    "        initial_kernels = [[k.clone().detach() for k in family] for family in Kernels]\n",
    "        print(\"Kernel in the first epoch:\")\n",
    "        for idx, family in enumerate(initial_kernels):\n",
    "            print(f\"Size {idx + 1}:\")\n",
    "            for k in family:\n",
    "                print(k)\n",
    "\n",
    "    # Apply L2 regularization\n",
    "    l2_penalty = sum(param.pow(2.0).sum() for param in model.parameters())\n",
    "    \n",
    "    # Apply Positive Penalty\n",
    "    positive_penalty = sum(torch.sum(F.relu(param)) for param in model.parameters())\n",
    "\n",
    "    # Calculating the loss including all penalties\n",
    "    loss_wp = loss + l2_lambda * l2_penalty + positive_lambda * positive_penalty\n",
    "\n",
    "    # Backpropagation\n",
    "    loss_wp.backward()\n",
    "\n",
    "    # Print the loss\n",
    "    \"\"\"\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss_wp.item()}')\n",
    "\n",
    "    # Print gradients for debugging\n",
    "    print(\"Gradients:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            print(f\"Gradient of {name}: {param.grad}\")\n",
    "        else:\n",
    "            print(f\"Gradient of {name} is None.\")\n",
    "    \"\"\"\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Append the loss to the list\n",
    "    losses.append(loss_wp.item())\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss_wp.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# Plot loss curve\n",
    "plt.plot(range(1, num_epochs + 1), losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel at the latest epoch:\n",
      "Family 1:\n",
      "tensor([-0.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([1.])\n",
      "tensor([1.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "tensor([-0.])\n",
      "Family 2:\n",
      "tensor([1., -0.])\n",
      "tensor([1., -0.])\n",
      "tensor([1., 1.])\n",
      "tensor([-0., -0.])\n",
      "tensor([-0., -0.])\n",
      "tensor([1., -0.])\n",
      "tensor([1., -0.])\n",
      "tensor([1., 1.])\n",
      "tensor([-0., 1.])\n",
      "tensor([-0., 1.])\n",
      "tensor([-0., -0.])\n",
      "tensor([1., 1.])\n",
      "tensor([-0., -0.])\n",
      "tensor([-0., -0.])\n",
      "tensor([-0., -0.])\n",
      "tensor([-0., -0.])\n",
      "tensor([1., -0.])\n",
      "tensor([-0., 1.])\n",
      "tensor([-0., 1.])\n",
      "tensor([-0., -0.])\n",
      "\n",
      "Comparison of initial and final SubKernels:\n",
      "Family 1:\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([1.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([1.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([1.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([1.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([1.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([1.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([1.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([1.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0.])\n",
      "Final SubKernel: tensor([-0.])\n",
      "\n",
      "Family 2:\n",
      "Initial SubKernel: tensor([1., 1.])\n",
      "Final SubKernel: tensor([1., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([1., -0.])\n",
      "Final SubKernel: tensor([1., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([1., 1.])\n",
      "Final SubKernel: tensor([1., 1.])\n",
      "\n",
      "Initial SubKernel: tensor([1., -0.])\n",
      "Final SubKernel: tensor([-0., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([1., 1.])\n",
      "Final SubKernel: tensor([-0., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0., -0.])\n",
      "Final SubKernel: tensor([1., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0., 1.])\n",
      "Final SubKernel: tensor([1., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([1., -0.])\n",
      "Final SubKernel: tensor([1., 1.])\n",
      "\n",
      "Initial SubKernel: tensor([1., -0.])\n",
      "Final SubKernel: tensor([-0., 1.])\n",
      "\n",
      "Initial SubKernel: tensor([1., -0.])\n",
      "Final SubKernel: tensor([-0., 1.])\n",
      "\n",
      "Initial SubKernel: tensor([1., -0.])\n",
      "Final SubKernel: tensor([-0., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0., 1.])\n",
      "Final SubKernel: tensor([1., 1.])\n",
      "\n",
      "Initial SubKernel: tensor([-0., 1.])\n",
      "Final SubKernel: tensor([-0., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0., 1.])\n",
      "Final SubKernel: tensor([-0., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([1., 1.])\n",
      "Final SubKernel: tensor([-0., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0., 1.])\n",
      "Final SubKernel: tensor([-0., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([-0., -0.])\n",
      "Final SubKernel: tensor([1., -0.])\n",
      "\n",
      "Initial SubKernel: tensor([1., -0.])\n",
      "Final SubKernel: tensor([-0., 1.])\n",
      "\n",
      "Initial SubKernel: tensor([-0., 1.])\n",
      "Final SubKernel: tensor([-0., 1.])\n",
      "\n",
      "Initial SubKernel: tensor([1., 1.])\n",
      "Final SubKernel: tensor([-0., -0.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print kernels at the latest epoch for comparison\n",
    "print(\"\\nKernel at the latest epoch:\")\n",
    "final_kernels = [[k.clone().detach() for k in family] for family in Kernels]\n",
    "for idx, family in enumerate(final_kernels):\n",
    "    print(f\"Family {idx + 1}:\")\n",
    "    for k in family:\n",
    "        print(k)\n",
    "\n",
    "# Comparison of initial and final subkernels\n",
    "print(\"\\nComparison of initial and final SubKernels:\")\n",
    "for idx, (initial_family, final_family) in enumerate(zip(initial_kernels, final_kernels)):\n",
    "    print(f\"Family {idx + 1}:\")\n",
    "    for k_init, k_final in zip(initial_family, final_family):\n",
    "        print(f\"Initial SubKernel: {k_init}\")\n",
    "        print(f\"Final SubKernel: {k_final}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final verification of gradients after training:\n",
      "Gradienti di kernels.0.Ks.0: tensor([-0.0017])\n",
      "Gradienti di kernels.0.Ks.1: tensor([ 0.0003, -0.0012])\n",
      "Gradienti di kernels.1.Ks.0: tensor([-9.1706e-06])\n",
      "Gradienti di kernels.1.Ks.1: tensor([-8.0140e-06, -4.9740e-05])\n",
      "Gradienti di kernels.2.Ks.0: tensor([0.0002])\n",
      "Gradienti di kernels.2.Ks.1: tensor([0.0243, 0.0151])\n",
      "Gradienti di kernels.3.Ks.0: tensor([-0.0015])\n",
      "Gradienti di kernels.3.Ks.1: tensor([-0.0066, -0.0012])\n",
      "Gradienti di kernels.4.Ks.0: tensor([0.0001])\n",
      "Gradienti di kernels.4.Ks.1: tensor([-0.0008, -0.0003])\n",
      "Gradienti di kernels.5.Ks.0: tensor([0.0013])\n",
      "Gradienti di kernels.5.Ks.1: tensor([ 0.0003, -0.0203])\n",
      "Gradienti di kernels.6.Ks.0: tensor([-0.0001])\n",
      "Gradienti di kernels.6.Ks.1: tensor([ 0.0006, -0.0005])\n",
      "Gradienti di kernels.7.Ks.0: tensor([-4.4957e-05])\n",
      "Gradienti di kernels.7.Ks.1: tensor([0.0010, 0.0001])\n",
      "Gradienti di kernels.8.Ks.0: tensor([0.0004])\n",
      "Gradienti di kernels.8.Ks.1: tensor([-0.0036,  0.0022])\n",
      "Gradienti di kernels.9.Ks.0: tensor([-0.0062])\n",
      "Gradienti di kernels.9.Ks.1: tensor([-0.0062,  0.0008])\n",
      "Gradienti di kernels.10.Ks.0: tensor([0.0007])\n",
      "Gradienti di kernels.10.Ks.1: tensor([-0.0069, -0.0002])\n",
      "Gradienti di kernels.11.Ks.0: tensor([0.0058])\n",
      "Gradienti di kernels.11.Ks.1: tensor([0.0003, 0.0022])\n",
      "Gradienti di kernels.12.Ks.0: tensor([-0.0069])\n",
      "Gradienti di kernels.12.Ks.1: tensor([-3.8133e-05, -1.6277e-03])\n",
      "Gradienti di kernels.13.Ks.0: tensor([-6.8246e-05])\n",
      "Gradienti di kernels.13.Ks.1: tensor([-3.1047e-05, -6.6426e-03])\n",
      "Gradienti di kernels.14.Ks.0: tensor([-0.0178])\n",
      "Gradienti di kernels.14.Ks.1: tensor([-0.0023, -0.0002])\n",
      "Gradienti di kernels.15.Ks.0: tensor([-1.8438e-05])\n",
      "Gradienti di kernels.15.Ks.1: tensor([-1.3182e-03, -5.8146e-05])\n",
      "Gradienti di kernels.16.Ks.0: tensor([-0.0023])\n",
      "Gradienti di kernels.16.Ks.1: tensor([ 0.0012, -0.0002])\n",
      "Gradienti di kernels.17.Ks.0: tensor([-1.2494e-05])\n",
      "Gradienti di kernels.17.Ks.1: tensor([-0.0004,  0.0004])\n",
      "Gradienti di kernels.18.Ks.0: tensor([-0.0018])\n",
      "Gradienti di kernels.18.Ks.1: tensor([-0.0001,  0.0001])\n",
      "Gradienti di kernels.19.Ks.0: tensor([-0.0011])\n",
      "Gradienti di kernels.19.Ks.1: tensor([-4.9252e-03, -4.7548e-05])\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Final verification of gradients after training\n",
    "print(\"Final verification of gradients after training:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"Gradienti di {name}: {param.grad}\")\n",
    "    else:\n",
    "        print(f\"Gradienti di {name} sono None.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
